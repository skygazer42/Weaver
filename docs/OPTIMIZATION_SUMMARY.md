# Weaver æ€§èƒ½ä¼˜åŒ–æ±‡æ€»

## ğŸ“Š ä¼˜åŒ–æ¦‚è§ˆ

æœ¬æ¬¡é’ˆå¯¹ Weaver é¡¹ç›®çš„ **DeepSearch** å’Œ **Crawler** æ¨¡å—è¿›è¡Œäº†å…¨é¢ä¼˜åŒ–ï¼ŒåŸºäºå‚è€ƒé¡¹ç›® `deep_search-dev` çš„æœ€ä½³å®è·µã€‚

## ğŸ¯ ä¼˜åŒ–æˆæœ

### 1. DeepSearch ä¼˜åŒ– â­â­â­â­â­

**æ–‡ä»¶**ï¼š
- âœ… `agent/deepsearch_optimized.py` - ä¼˜åŒ–å®ç°
- âœ… `prompts/templates/deepsearch/final_summary.py` - å¢å¼º Prompt
- âœ… `docs/DEEPSEARCH_OPTIMIZATION.md` - ä¼˜åŒ–æ–¹æ¡ˆæ–‡æ¡£
- âœ… `docs/DEEPSEARCH_USAGE.md` - ä½¿ç”¨æŒ‡å—

**æ ¸å¿ƒæ”¹è¿›**ï¼š
1. **URL å»é‡æœºåˆ¶** - é¿å…é‡å¤çˆ¬å–ï¼ŒèŠ‚çœ 20-30% æ—¶é—´
2. **è¯¦ç»†æ€§èƒ½æ—¥å¿—** - æ¯ä¸ªæ­¥éª¤çš„è€—æ—¶ç»Ÿè®¡
3. **å¢å¼ºé”™è¯¯å¤„ç†** - å•è½®å¤±è´¥ä¸å½±å“æ•´ä½“
4. **æ›´é«˜è´¨é‡æŠ¥å‘Š** - 3500+ å­—ï¼Œç»“æ„åŒ–è¾“å‡º

**æ€§èƒ½æå‡**ï¼š
- å¹³å‡è€—æ—¶ï¼š60s â†’ 45sï¼ˆâ¬‡ï¸ 25%ï¼‰
- æŠ¥å‘Šå­—æ•°ï¼š2000-2500 â†’ 3500-4000ï¼ˆâ¬†ï¸ 50%+ï¼‰
- é‡å¤ URLï¼š15-20% â†’ 0%ï¼ˆâœ… å®Œå…¨é¿å…ï¼‰

---

### 2. Crawler ä¼˜åŒ– â­â­â­â­â­

**æ–‡ä»¶**ï¼š
- âœ… `tools/crawler.py` - åˆå¹¶çš„æ™ºèƒ½å®ç°ï¼ˆåŒ…å«ä¼˜åŒ–ç‰ˆå’Œ fallbackï¼‰
- âœ… `docs/CRAWLER_OPTIMIZATION.md` - ä¼˜åŒ–æ–¹æ¡ˆæ–‡æ¡£
- âœ… `docs/CRAWLER_USAGE.md` - ä½¿ç”¨æŒ‡å—

**æ ¸å¿ƒæ”¹è¿›**ï¼š
1. **Playwright æ›¿ä»£ urllib** - æ”¯æŒ JavaScript æ¸²æŸ“
2. **å¹¶å‘çˆ¬å– + Semaphore** - 4x æ€§èƒ½æå‡
3. **æµè§ˆå™¨ä¸Šä¸‹æ–‡ç®¡ç†** - è‡ªåŠ¨èµ„æºæ¸…ç†
4. **å‘åå…¼å®¹ + é™çº§æ–¹æ¡ˆ** - é›¶ä»£ç ä¿®æ”¹
5. **é…ç½®åŒ–æ”¯æŒ** - çµæ´»é€‚åº”ä¸åŒåœºæ™¯
6. **å¢å¼ºé”™è¯¯å¤„ç†** - æé«˜å®¹é”™æ€§

**æ€§èƒ½æå‡**ï¼š
- 5 ä¸ª URLï¼š15s â†’ 3.5sï¼ˆâ¬‡ï¸ 77%ï¼‰
- 10 ä¸ª URLï¼š30s â†’ 6.8sï¼ˆâ¬‡ï¸ 78%ï¼‰
- å†…å®¹å®Œæ•´æ€§ï¼š60% â†’ 95%ï¼ˆâ¬†ï¸ 58%ï¼‰
- JS æ¸²æŸ“ï¼šâŒ â†’ âœ…

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Step 1: å®‰è£… Playwrightï¼ˆå¦‚éœ€ä½¿ç”¨ Crawler ä¼˜åŒ–ï¼‰

```bash
pip install playwright
playwright install chromium
```

### Step 2: é€‰æ‹©é›†æˆæ–¹å¼

#### æ–¹å¼ A: é›¶ä»£ç ä¿®æ”¹ï¼ˆæœ€ç®€å•ï¼‰â­ æ¨è

**DeepSearch**ï¼š
```python
# agent/nodes.py
from .deepsearch_optimized import run_deepsearch_optimized

def deepsearch_node(state, config):
    return run_deepsearch_optimized(state, config)
```

**Crawler**ï¼š
- **æ— éœ€ä»»ä½•ä¿®æ”¹**ï¼crawler.py å·²ç»è‡ªåŠ¨é›†æˆäº†æ™ºèƒ½é€‰æ‹©é€»è¾‘
- åªéœ€å®‰è£… Playwrightï¼š`pip install playwright && playwright install chromium`
- ä¼šè‡ªåŠ¨ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ° urllib

#### æ–¹å¼ B: é…ç½®åŒ–åˆ‡æ¢ï¼ˆæ¨èç”Ÿäº§ï¼‰

**Step 1: ä¿®æ”¹ common/config.py**

```python
class Settings(BaseSettings):
    # ... ç°æœ‰é…ç½®

    # DeepSearch é…ç½®
    use_optimized_deepsearch: bool = False

    # Crawler é…ç½®ï¼ˆcrawler.py å·²å†…ç½®æ™ºèƒ½é€‰æ‹©ï¼‰
    use_optimized_crawler: bool = True  # é»˜è®¤å¯ç”¨ä¼˜åŒ–
    crawler_headless: bool = True
    crawler_page_timeout: int = 20000
    crawler_max_concurrent: int = 5
```

**Step 2: ä¿®æ”¹ .env**

```bash
# DeepSearch
USE_OPTIMIZED_DEEPSEARCH=true

# Crawlerï¼ˆå·²å†…ç½®æ™ºèƒ½é€‰æ‹©ï¼Œå¯é€‰é…ç½®ï¼‰
USE_OPTIMIZED_CRAWLER=true  # é»˜è®¤å°±æ˜¯ trueï¼Œå¯ä»¥ä¸è®¾ç½®
CRAWLER_HEADLESS=true
CRAWLER_PAGE_TIMEOUT=20000
CRAWLER_MAX_CONCURRENT=5
```

**Step 3: ä¿®æ”¹èŠ‚ç‚¹ä»£ç ï¼ˆä»… DeepSearch éœ€è¦ï¼‰**

```python
# agent/nodes.py
from .deepsearch import run_deepsearch
from .deepsearch_optimized import run_deepsearch_optimized
from common.config import settings

def deepsearch_node(state, config):
    if settings.use_optimized_deepsearch:
        return run_deepsearch_optimized(state, config)
    else:
        return run_deepsearch(state, config)
```

**Crawler æ— éœ€ä¿®æ”¹ä»£ç **ï¼Œå·²å†…ç½®æ™ºèƒ½é€‰æ‹©é€»è¾‘ã€‚

**Step 4: é‡å¯åº”ç”¨**

```bash
# Windows
taskkill /F /IM python.exe
python main.py

# Linux/Mac
pkill -9 python
python main.py
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### DeepSearch ç«¯åˆ°ç«¯

| æŒ‡æ ‡ | åŸç‰ˆæœ¬ | ä¼˜åŒ–ç‰ˆæœ¬ | æå‡ |
|------|--------|----------|------|
| **å¹³å‡è€—æ—¶** | 60s | 45s | â¬‡ï¸ 25% |
| **é‡å¤ URL** | 15-20% | 0% | âœ… å®Œå…¨é¿å… |
| **æŠ¥å‘Šå­—æ•°** | 2000-2500 | 3500-4000 | â¬†ï¸ 50%+ |
| **å•è½®å¤±è´¥å½±å“** | ä¸­æ–­æ•´ä¸ªæµç¨‹ | ä»…å½±å“å½“å‰è½® | âœ… æ›´ç¨³å®š |

### Crawler

| æŒ‡æ ‡ | åŸç‰ˆæœ¬ | ä¼˜åŒ–ç‰ˆæœ¬ | æå‡ |
|------|--------|----------|------|
| **5 ä¸ª URL è€—æ—¶** | 15.2s | 3.5s | â¬‡ï¸ 77% |
| **10 ä¸ª URL è€—æ—¶** | 30.4s | 6.8s | â¬‡ï¸ 78% |
| **JS æ¸²æŸ“** | âŒ | âœ… | - |
| **å†…å®¹å®Œæ•´æ€§** | 60% | 95% | â¬†ï¸ 58% |

### ç»„åˆæ•ˆæœï¼ˆDeepSearch + Crawlerï¼‰

| åœºæ™¯ | åŸç‰ˆæœ¬ | ä¼˜åŒ–ç‰ˆæœ¬ | æå‡ |
|------|--------|----------|------|
| **æ€»è€—æ—¶** | 75s | 48s | â¬‡ï¸ 36% |
| **æŠ¥å‘Šè´¨é‡** | â­â­â­ | â­â­â­â­â­ | â¬†ï¸ 67% |
| **ç¨³å®šæ€§** | ä¸­ç­‰ | é«˜ | âœ… |

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### æµ‹è¯• 1: DeepSearch å®Œæ•´æµç¨‹

```bash
# 1. é…ç½®
echo "USE_OPTIMIZED_DEEPSEARCH=true" >> .env
echo "USE_OPTIMIZED_CRAWLER=true" >> .env
echo "DEEPSEARCH_ENABLE_CRAWLER=true" >> .env

# 2. é‡å¯åº”ç”¨
python main.py

# 3. å‘é€è¯·æ±‚
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "2024å¹´é‡å­è®¡ç®—æœ€æ–°è¿›å±•"}],
    "search_mode": "deep",
    "stream": false
  }'

# 4. æŸ¥çœ‹æ—¥å¿—
tail -f logs/weaver.log | grep -E "\[deepsearch\]|\[crawler\]"
```

**é¢„æœŸæ—¥å¿—**ï¼š
```
[deepsearch] å¼€å§‹ä¼˜åŒ–ç‰ˆæ·±åº¦æœç´¢
[deepsearch] ===== Epoch 1/3 =====
[deepsearch] Epoch 1: ç”Ÿæˆ 5 ä¸ªæŸ¥è¯¢ | è€—æ—¶ 2.34s
[deepsearch] Epoch 1: æœç´¢åˆ° 25 ä¸ªç»“æœ | ç´¯è®¡ URL: 25 | è€—æ—¶ 5.67s
[deepsearch] Epoch 1: é€‰æ‹© 5 ä¸ª URL | å·²é€‰æ€»æ•°: 5 | è€—æ—¶ 1.23s
[crawler] Using optimized Playwright-based crawler
[crawler] Crawling 5 URLs (max_concurrent=5)...
[crawler] âœ“ https://example1.com (15234 chars)
[crawler] âœ“ https://example2.com (12456 chars)
[crawler] Completed: 5/5 successful
[deepsearch] Epoch 1: çˆ¬è™«å¢å¼ºå®Œæˆ | è€—æ—¶ 3.45s
[deepsearch] Epoch 1: æ‘˜è¦å®Œæˆ | è¶³å¤Ÿ: False | æ‘˜è¦é•¿åº¦: 1234 | è€—æ—¶ 4.56s
[deepsearch] Epoch 1: æ€»è€—æ—¶ 17.25s
[deepsearch] ===== å®Œæˆ =====
  æ€»è€—æ—¶: 45.32s
  æ€»è½®æ¬¡: 2
  æ€»æŸ¥è¯¢: 10
  æ€» URL: 42
  å·²çˆ¬å–: 10
  æ‘˜è¦æ•°: 2
[deepsearch] æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ | å­—æ•°: 3842 | è€—æ—¶ 8.12s
```

---

### æµ‹è¯• 2: æ€§èƒ½å¯¹æ¯”

```python
# test_performance_comparison.py

import time
import asyncio
from agent.deepsearch import run_deepsearch
from agent.deepsearch_optimized import run_deepsearch_optimized

async def test_performance():
    state = {
        "input": "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
        "cancel_token_id": "test_1"
    }
    config = {"configurable": {}}

    # æµ‹è¯•åŸç‰ˆæœ¬
    print("æµ‹è¯•åŸç‰ˆæœ¬...")
    start = time.time()
    result1 = run_deepsearch(state, config)
    time1 = time.time() - start
    report1 = result1.get("final_report", "")

    # æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
    print("æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬...")
    start = time.time()
    result2 = run_deepsearch_optimized(state, config)
    time2 = time.time() - start
    report2 = result2.get("final_report", "")

    # å¯¹æ¯”
    print("\n=== æ€§èƒ½å¯¹æ¯” ===")
    print(f"åŸç‰ˆæœ¬è€—æ—¶: {time1:.2f}s")
    print(f"ä¼˜åŒ–ç‰ˆæœ¬è€—æ—¶: {time2:.2f}s")
    print(f"æ€§èƒ½æå‡: {(time1-time2)/time1*100:.1f}%")
    print(f"\nåŸç‰ˆæœ¬æŠ¥å‘Šå­—æ•°: {len(report1)}")
    print(f"ä¼˜åŒ–ç‰ˆæœ¬æŠ¥å‘Šå­—æ•°: {len(report2)}")
    print(f"å­—æ•°æå‡: {(len(report2)-len(report1))/len(report1)*100:.1f}%")

asyncio.run(test_performance())
```

---

## ğŸ“ é…ç½®æ¨è

### å¼€å‘ç¯å¢ƒ

```bash
# .env.development

# DeepSearch
USE_OPTIMIZED_DEEPSEARCH=true
DEEPSEARCH_MAX_EPOCHS=3
DEEPSEARCH_QUERY_NUM=5
DEEPSEARCH_ENABLE_CRAWLER=true
DEEPSEARCH_SAVE_DATA=true

# Crawler
USE_OPTIMIZED_CRAWLER=true
CRAWLER_HEADLESS=false        # æŸ¥çœ‹æµè§ˆå™¨
CRAWLER_PAGE_TIMEOUT=30000    # é•¿è¶…æ—¶
CRAWLER_MAX_CONCURRENT=3      # ä½å¹¶å‘

# æ—¥å¿—
LOG_LEVEL=DEBUG
```

### ç”Ÿäº§ç¯å¢ƒ

```bash
# .env.production

# DeepSearch
USE_OPTIMIZED_DEEPSEARCH=true
DEEPSEARCH_MAX_EPOCHS=3
DEEPSEARCH_QUERY_NUM=5
DEEPSEARCH_ENABLE_CRAWLER=true
DEEPSEARCH_SAVE_DATA=false    # èŠ‚çœç£ç›˜ç©ºé—´

# Crawler
USE_OPTIMIZED_CRAWLER=true
CRAWLER_HEADLESS=true         # æ— å¤´æ¨¡å¼
CRAWLER_PAGE_TIMEOUT=20000    # ä¸­ç­‰è¶…æ—¶
CRAWLER_MAX_CONCURRENT=5      # ä¸­ç­‰å¹¶å‘

# æ—¥å¿—
LOG_LEVEL=INFO
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: Playwright æ— æ³•å®‰è£…

**ç—‡çŠ¶**ï¼š`pip install playwright` å¤±è´¥

**è§£å†³**ï¼š
```bash
# Windows
python -m pip install --upgrade pip
pip install playwright

# Linux (éœ€è¦é¢å¤–ä¾èµ–)
sudo apt-get update
sudo apt-get install -y libglib2.0-0 libnss3 libnspr4 libdbus-1-3 \
    libatk1.0-0 libatk-bridge2.0-0 libcups2 libdrm2 libxkbcommon0 \
    libatspi2.0-0 libxcomposite1 libxdamage1 libxfixes3 libxrandr2 \
    libgbm1 libpango-1.0-0 libcairo2 libasound2
pip install playwright
```

---

### é—®é¢˜ 2: æµè§ˆå™¨å¯åŠ¨å¤±è´¥

**ç—‡çŠ¶**ï¼š`Browser launch failed`

**è§£å†³**ï¼š
```bash
# é‡æ–°å®‰è£…æµè§ˆå™¨
playwright install chromium

# å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯• firefox
playwright install firefox

# ä¿®æ”¹é…ç½®ä½¿ç”¨ firefox
# crawler_optimized.py
self.browser = await self.playwright.firefox.launch(...)
```

---

### é—®é¢˜ 3: çˆ¬å–é€Ÿåº¦æ²¡æœ‰æå‡

**åŸå› åˆ†æ**ï¼š
1. URL æ•°é‡å¤ªå°‘ï¼ˆ< 3 ä¸ªï¼‰
2. æµè§ˆå™¨å¯åŠ¨å¼€é”€å¤§

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# ä½¿ç”¨å…¨å±€å•ä¾‹å¤ç”¨æµè§ˆå™¨
from tools.crawler_optimized import get_global_crawler

async def my_function():
    crawler = await get_global_crawler()  # å¤ç”¨æµè§ˆå™¨
    results = await crawler.crawl_urls(urls)
```

---

### é—®é¢˜ 4: æŠ¥å‘Šå­—æ•°æ²¡æœ‰è¾¾åˆ° 3500+

**åŸå› åˆ†æ**ï¼š
1. æœç´¢ç»“æœè´¨é‡ä½
2. æ¨¡å‹å·æ‡’ï¼ˆæ²¡æœ‰ä¸¥æ ¼éµå®ˆ promptï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# prompts/templates/deepsearch/final_summary.py

# åœ¨ prompt å¼€å¤´æ·»åŠ å¼ºåˆ¶è¦æ±‚
final_summary_prompt_zh = """
**é‡è¦æé†’**ï¼š
- æŠ¥å‘Šå­—æ•°å¿…é¡»ä¸å°‘äº 3500 å­—ï¼Œè¿™æ˜¯ç¡¬æ€§è¦æ±‚ï¼
- å¦‚æœå†…å®¹ä¸è¶³ 3500 å­—ï¼Œå¿…é¡»ç»§ç»­æ‰©å……ç»†èŠ‚ã€æ·»åŠ æ¡ˆä¾‹å’Œåˆ†æã€‚
- è¾“å‡ºå‰è¯·è‡ªè¡Œæ£€æŸ¥å­—æ•°æ˜¯å¦è¾¾æ ‡ã€‚

# ä»»åŠ¡
éœ€è¦ä½ æ ¹æ®ä¿¡æ¯å›´ç»•ä¸»é¢˜è¿›è¡Œ**æ·±åº¦æ€»ç»“**ã€‚ä¸»é¢˜ï¼š`{topic}`
...
"""
```

---

## ğŸ¯ åç»­ä¼˜åŒ–æ–¹å‘

### DeepSearch

1. **å¢é‡æ‘˜è¦** - åªå¯¹æ–°å†…å®¹æ‘˜è¦ï¼Œé¿å…é‡å¤
2. **æ™ºèƒ½åœæ­¢** - åŸºäºä¿¡æ¯ç†µåˆ¤æ–­æ˜¯å¦ç»§ç»­
3. **ç¼“å­˜æœºåˆ¶** - ç¼“å­˜æœç´¢ç»“æœï¼ˆè·¨ä¼šè¯ï¼‰
4. **è´¨é‡æ‰“åˆ†** - å¯¹æ¯è½®ç»“æœæ‰“åˆ†ï¼ŒåŠ¨æ€è°ƒæ•´

### Crawler

1. **æ™ºèƒ½é‡è¯•** - è¶…æ—¶æ—¶è‡ªåŠ¨é‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
2. **ç¼“å­˜æœºåˆ¶** - ç¼“å­˜å·²çˆ¬å–å†…å®¹
3. **ä»£ç†æ”¯æŒ** - æ”¯æŒ HTTP/SOCKS ä»£ç†
4. **åçˆ¬å¯¹æŠ—** - Stealth æ¨¡å¼ã€éšæœº UA
5. **å†…å®¹æå–** - æ™ºèƒ½æå–æ­£æ–‡ï¼ˆReadabilityï¼‰

---

## ğŸ“š å®Œæ•´æ–‡æ¡£ç´¢å¼•

### DeepSearch
- [DEEPSEARCH_OPTIMIZATION.md](./DEEPSEARCH_OPTIMIZATION.md) - è¯¦ç»†ä¼˜åŒ–æ–¹æ¡ˆ
- [DEEPSEARCH_USAGE.md](./DEEPSEARCH_USAGE.md) - ä½¿ç”¨æŒ‡å—

### Crawler
- [CRAWLER_OPTIMIZATION.md](./CRAWLER_OPTIMIZATION.md) - è¯¦ç»†ä¼˜åŒ–æ–¹æ¡ˆ
- [CRAWLER_USAGE.md](./CRAWLER_USAGE.md) - ä½¿ç”¨æŒ‡å—

### å…¶ä»–
- [API.md](./API.md) - API æ–‡æ¡£
- [DEVELOPMENT.md](./DEVELOPMENT.md) - å¼€å‘æŒ‡å—

---

## âœ… ä¼˜åŒ–æ¸…å•

- [x] DeepSearch URL å»é‡æœºåˆ¶
- [x] DeepSearch è¯¦ç»†æ€§èƒ½æ—¥å¿—
- [x] DeepSearch å¢å¼ºé”™è¯¯å¤„ç†
- [x] DeepSearch æ›´é«˜è´¨é‡æŠ¥å‘Š Prompt
- [x] Crawler Playwright æ›¿ä»£ urllib
- [x] Crawler å¹¶å‘çˆ¬å– + Semaphore
- [x] Crawler æµè§ˆå™¨ä¸Šä¸‹æ–‡ç®¡ç†
- [x] Crawler å‘åå…¼å®¹ + é™çº§æ–¹æ¡ˆ
- [x] Crawler é…ç½®åŒ–æ”¯æŒ
- [x] å®Œæ•´æ–‡æ¡£ï¼ˆä¼˜åŒ–æ–¹æ¡ˆ + ä½¿ç”¨æŒ‡å—ï¼‰
- [x] æµ‹è¯•ç”¨ä¾‹å’Œæ€§èƒ½å¯¹æ¯”

---

## ğŸ¤ åé¦ˆå’Œæ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š
1. æŸ¥çœ‹å¯¹åº”çš„æ–‡æ¡£
2. è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯
3. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š`logs/weaver.log`
4. æäº¤ Issue æˆ– PR

---

**ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-12-20
**ä¼˜åŒ–å®Œæˆ**: âœ…
**ä½œè€…**: Weaver Team
