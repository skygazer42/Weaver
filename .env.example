# ===== Models & Gateways =====
# OpenAI / OpenAI-compatible gateway API key
OPENAI_API_KEY=sk-...
# Custom OpenAI-compatible base URL (empty uses official), e.g. https://api.openai.com/v1
OPENAI_BASE_URL=
# Use Azure OpenAI
USE_AZURE=false
# Azure settings
AZURE_API_KEY=
AZURE_ENDPOINT=
AZURE_API_VERSION=2025-03-01-preview
# LLM request timeout (seconds)
OPENAI_TIMEOUT=60
# Extra request body (JSON string). Leave as {} to ignore.
OPENAI_EXTRA_BODY={}
# Anthropic API key (optional)
ANTHROPIC_API_KEY=sk-ant-...

# ===== Tools / Third Party =====
# Tavily search
TAVILY_API_KEY=tvly-...
# E2B code execution
E2B_API_KEY=e2b_...
# DashScope (ASR/TTS)
DASHSCOPE_API_KEY=

# ===== Memory / Long-term Storage =====
# Optional Mem0 API key (if enabled)
MEM0_API_KEY=
# Enable long-term memory (Mem0 or fallback to local JSON)
ENABLE_MEMORY=false
# Memory namespace and user id
MEMORY_NAMESPACE=default
MEMORY_USER_ID=default_user
# Memory limits
MEMORY_MAX_ENTRIES=20
MEMORY_TOP_K=5

# LangGraph store backend (optional)
# memory | postgres | redis
MEMORY_STORE_BACKEND=memory
# Connection string for store backend when using postgres/redis
MEMORY_STORE_URL=

# ===== Database =====
# Postgres connection string (empty -> in-memory checkpointer)
DATABASE_URL=postgresql://manus:manus_dev_password@localhost:5432/manus_db

# ===== Runtime / Observability =====
# dev | test | prod
APP_ENV=dev
# Expose /metrics in Prometheus format
ENABLE_PROMETHEUS=false

# ===== App Basics =====
# Debug mode
DEBUG=True
# Allowed CORS origins (comma separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:3001
# LangGraph interrupt-before node list (comma separated, e.g. writer,human_review)
INTERRUPT_BEFORE_NODES=

# ===== Logging =====
# Log level: DEBUG / INFO / WARNING / ERROR / CRITICAL
LOG_LEVEL=INFO
# Log file path
LOG_FILE=logs/weaver.log
# Max single log file size (bytes)
LOG_MAX_BYTES=10485760
# Number of backup log files
LOG_BACKUP_COUNT=5
# Log format
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s
# Enable file logging
ENABLE_FILE_LOGGING=true
# Enable structured JSON logging
ENABLE_JSON_LOGGING=false

# ===== LangGraph Behavior =====
# Require human review before final report
HUMAN_REVIEW=false
# Require approval before executing tools
TOOL_APPROVAL=false
# Max revisions
MAX_REVISIONS=2
# Tool middleware controls: retries / limits / history trimming
TOOL_RETRY=false
TOOL_RETRY_MAX_ATTEMPTS=3
TOOL_RETRY_BACKOFF=1.5
TOOL_CALL_LIMIT=0
STRIP_TOOL_MESSAGES=false
TOOL_SELECTOR=false
TOOL_SELECTOR_MODEL=gpt-4o-mini
TOOL_SELECTOR_MAX_TOOLS=3
TOOL_SELECTOR_ALWAYS_INCLUDE=
TOOL_SELECTOR_PROMPT=

# ===== Short-term Memory (trimming & summarization) =====
TRIM_MESSAGES=false
TRIM_MESSAGES_KEEP_FIRST=2
TRIM_MESSAGES_KEEP_LAST=8
SUMMARY_MESSAGES=false
SUMMARY_MESSAGES_TRIGGER=12
SUMMARY_MESSAGES_KEEP_LAST=4
SUMMARY_MESSAGES_MODEL=gpt-4o-mini
SUMMARY_MESSAGES_WORD_LIMIT=200

# ===== Deepsearch =====
DEEPSEARCH_MAX_EPOCHS=3
DEEPSEARCH_QUERY_NUM=5
DEEPSEARCH_RESULTS_PER_QUERY=5
DEEPSEARCH_ENABLE_CRAWLER=false
DEEPSEARCH_SAVE_DATA=false
DEEPSEARCH_SAVE_DIR=eval/deepsearch_data

# ===== MCP (optional multi-tool bridge) =====
ENABLE_MCP=false
# MCP server config JSON, e.g. {"math": {"transport": "stdio", "command": "python", "args": ["/path/to/math_service.py"]}}
MCP_SERVERS={}
