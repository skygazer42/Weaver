===== 模型与网关 =====
# OpenAI / 兼容网关主密钥
OPENAI_API_KEY=sk-...
# 自定义 OpenAI 兼容网关；留空默认官方，例如 https://api.openai.com/v1
OPENAI_BASE_URL=
# 是否使用 Azure OpenAI
USE_AZURE=false
# Azure 相关参数
AZURE_API_KEY=
AZURE_ENDPOINT=
AZURE_API_VERSION=2025-03-01-preview
# LLM 请求超时时间（秒）
OPENAI_TIMEOUT=60
# 额外请求体（JSON 字符串，留空忽略）
OPENAI_EXTRA_BODY={}
# Anthropic Key（若需切换模型）
ANTHROPIC_API_KEY=sk-ant-...

===== 工具 / 第三方 =====
# Tavily 搜索
TAVILY_API_KEY=tvly-...
# E2B 代码执行
E2B_API_KEY=e2b_...
# 阿里云 DashScope（ASR/TTS）
DASHSCOPE_API_KEY=

===== 记忆 / 长期存储 =====
# mem0 可选密钥，未安装会退回本地 JSON
MEM0_API_KEY=
# 是否启用长记忆
ENABLE_MEMORY=false
# 记忆命名空间与用户
MEMORY_NAMESPACE=default
MEMORY_USER_ID=default_user
# 记忆条目上限与召回数量
MEMORY_MAX_ENTRIES=20
MEMORY_TOP_K=5

===== 数据库 =====
# Postgres 连接串（空则用内存 checkpointer）
DATABASE_URL=postgresql://manus:manus_dev_password@localhost:5432/manus_db

===== 应用基础配置 =====
# 调试模式
DEBUG=True
# 允许的跨域来源（逗号分隔）
CORS_ORIGINS=http://localhost:3000,http://localhost:3001
# LangGraph 中断节点列表（逗号分隔，如 writer,human_review）
INTERRUPT_BEFORE_NODES=

===== 日志配置 =====
# 日志级别: DEBUG / INFO / WARNING / ERROR / CRITICAL
LOG_LEVEL=INFO
# 日志文件路径
LOG_FILE=logs/weaver.log
# 单个日志文件最大大小（字节）
LOG_MAX_BYTES=10485760
# 历史日志文件数量
LOG_BACKUP_COUNT=5
# 日志格式
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s
# 是否写入文件
ENABLE_FILE_LOGGING=true
# 是否 JSON 结构化日志
ENABLE_JSON_LOGGING=false

===== LangGraph 行为 =====
# 是否需要人工复核节点
HUMAN_REVIEW=false
# 是否要求工具调用前审批
TOOL_APPROVAL=false
# 报告最多修订次数
MAX_REVISIONS=2

===== 短期记忆（消息修剪与摘要）=====
# 是否开启消息修剪
TRIM_MESSAGES=false
# 保留的最前消息数量（通常是系统提示）
TRIM_MESSAGES_KEEP_FIRST=2
# 保留的最新消息数量
TRIM_MESSAGES_KEEP_LAST=8
# 是否对中间历史做摘要
SUMMARY_MESSAGES=false
# 触发摘要的消息条数阈值
SUMMARY_MESSAGES_TRIGGER=12
# 摘要后保留的最新消息数量
SUMMARY_MESSAGES_KEEP_LAST=4
# 摘要使用的模型
SUMMARY_MESSAGES_MODEL=gpt-4o-mini
# 摘要最大字数（近似）
SUMMARY_MESSAGES_WORD_LIMIT=200

===== Deepsearch 深度搜索 =====
# 最大迭代轮次
DEEPSEARCH_MAX_EPOCHS=3
# 每轮生成子查询数量
DEEPSEARCH_QUERY_NUM=5
# 每个查询保留结果数量
DEEPSEARCH_RESULTS_PER_QUERY=5
# 是否启用轻量爬虫补全文本
DEEPSEARCH_ENABLE_CRAWLER=false
# 是否保存深搜过程数据
DEEPSEARCH_SAVE_DATA=false
# 深搜数据保存目录
DEEPSEARCH_SAVE_DIR=eval/deepsearch_data

===== MCP（可选多模态工具桥）=====
# 是否启用 MCP
ENABLE_MCP=false
# MCP 服务器配置 JSON，例如 {"math":{"transport":"stdio","command":"python","args":["/path/to/math_service.py"]}}
MCP_SERVERS={}
