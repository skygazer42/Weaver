"""
Test script to compare Simple vs Enhanced prompts.

Usage:
    python test_prompt_comparison.py
"""

import os
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from datetime import datetime

from agent.prompts.prompt_manager import PromptManager


def test_prompt_lengths():
    """Test and compare prompt lengths."""
    print("=" * 80)
    print("PROMPT LENGTH COMPARISON")
    print("=" * 80)

    # Simple prompts
    simple_mgr = PromptManager(prompt_style="simple")
    simple_agent = simple_mgr.get_agent_prompt()
    simple_writer = simple_mgr.get_writer_prompt()

    print(f"\nüìä Simple Prompts:")
    print(f"  Agent:  {len(simple_agent):>6} chars")
    print(f"  Writer: {len(simple_writer):>6} chars")
    print(f"  Total:  {len(simple_agent) + len(simple_writer):>6} chars")

    # Enhanced prompts
    enhanced_mgr = PromptManager(prompt_style="enhanced")
    enhanced_agent = enhanced_mgr.get_agent_prompt(context={
        "current_time": datetime.now(),
        "enabled_tools": ["web_search", "execute_python_code", "crawl_url"]
    })
    enhanced_writer = enhanced_mgr.get_writer_prompt()

    print(f"\nüìà Enhanced Prompts:")
    print(f"  Agent:  {len(enhanced_agent):>6} chars (~{len(enhanced_agent)//4} tokens)")
    print(f"  Writer: {len(enhanced_writer):>6} chars (~{len(enhanced_writer)//4} tokens)")
    print(f"  Total:  {len(enhanced_agent) + len(enhanced_writer):>6} chars (~{(len(enhanced_agent) + len(enhanced_writer))//4} tokens)")

    # Comparison
    agent_increase = ((len(enhanced_agent) - len(simple_agent)) / len(simple_agent)) * 100
    writer_increase = ((len(enhanced_writer) - len(simple_writer)) / len(simple_writer)) * 100

    print(f"\nüìä Size Increase:")
    print(f"  Agent:  +{agent_increase:.1f}%")
    print(f"  Writer: +{writer_increase:.1f}%")

    # Cost estimation (GPT-4 rates)
    simple_tokens = (len(simple_agent) + len(simple_writer)) // 4
    enhanced_tokens = (len(enhanced_agent) + len(enhanced_writer)) // 4
    cost_per_1k = 0.00003  # GPT-4 input cost

    simple_cost = (simple_tokens / 1000) * cost_per_1k
    enhanced_cost = (enhanced_tokens / 1000) * cost_per_1k

    print(f"\nüí∞ Cost per Call (GPT-4 input rates):")
    print(f"  Simple:   ${simple_cost:.6f}")
    print(f"  Enhanced: ${enhanced_cost:.6f}")
    print(f"  Increase: ${enhanced_cost - simple_cost:.6f} (+{((enhanced_cost - simple_cost)/simple_cost)*100:.1f}%)")

    print(f"\nüí∏ Cost for 1000 Calls:")
    print(f"  Simple:   ${simple_cost * 1000:.4f}")
    print(f"  Enhanced: ${enhanced_cost * 1000:.4f}")
    print(f"  Increase: ${(enhanced_cost - simple_cost) * 1000:.4f}")


def test_prompt_content():
    """Display and compare prompt content."""
    print("\n" + "=" * 80)
    print("PROMPT CONTENT PREVIEW")
    print("=" * 80)

    # Enhanced Agent Prompt
    enhanced_mgr = PromptManager(prompt_style="enhanced")
    enhanced_agent = enhanced_mgr.get_agent_prompt(context={
        "current_time": datetime.now(),
        "enabled_tools": ["web_search", "execute_python_code"]
    })

    print("\nüéØ Enhanced Agent Prompt (first 500 chars):")
    print("-" * 80)
    print(enhanced_agent[:500] + "...")

    # Enhanced Writer Prompt
    enhanced_writer = enhanced_mgr.get_writer_prompt()

    print("\n‚úçÔ∏è Enhanced Writer Prompt (first 500 chars):")
    print("-" * 80)
    print(enhanced_writer[:500] + "...")

    # Show key sections
    print("\nüìã Key Sections in Enhanced Agent Prompt:")
    sections = [
        "# 1. CORE CAPABILITIES",
        "# 2. EXECUTION PRINCIPLES",
        "## 2.1 TOOL USAGE BEST PRACTICES",
        "## 2.2 QUALITY STANDARDS",
        "# 3. WORKFLOW GUIDELINES",
        "# 4. CRITICAL RULES",
    ]

    for section in sections:
        if section in enhanced_agent:
            print(f"  ‚úì {section}")
        else:
            print(f"  ‚úó {section} (not found)")

    print("\nüìã Key Sections in Enhanced Writer Prompt:")
    sections = [
        "# YOUR ROLE",
        "# WRITING GUIDELINES",
        "## Structure",
        "## Citation Style",
        "## Content Quality",
        "# TOOLS AVAILABLE",
        "# FINAL CHECK",
    ]

    for section in sections:
        if section in enhanced_writer:
            print(f"  ‚úì {section}")
        else:
            print(f"  ‚úó {section} (not found)")


def test_context_injection():
    """Test context-aware prompt building."""
    print("\n" + "=" * 80)
    print("CONTEXT INJECTION TEST")
    print("=" * 80)

    enhanced_mgr = PromptManager(prompt_style="enhanced")

    # Test with different contexts
    contexts = [
        {
            "name": "Basic",
            "context": None
        },
        {
            "name": "With Time",
            "context": {
                "current_time": datetime.now()
            }
        },
        {
            "name": "With Time + Tools",
            "context": {
                "current_time": datetime.now(),
                "enabled_tools": ["web_search", "execute_python_code", "crawl_url"]
            }
        },
    ]

    for ctx_info in contexts:
        prompt = enhanced_mgr.get_agent_prompt(context=ctx_info["context"])
        print(f"\nüì¶ {ctx_info['name']} Context:")
        print(f"  Length: {len(prompt)} chars")

        # Check for context-specific content
        if ctx_info["context"]:
            if "current_time" in ctx_info["context"]:
                has_date = "CURRENT DATE/TIME" in prompt or "Today's date" in prompt
                print(f"  Date Info: {'‚úì Injected' if has_date else '‚úó Missing'}")

            if "enabled_tools" in ctx_info["context"]:
                has_tools = "AVAILABLE TOOLS" in prompt
                print(f"  Tools Info: {'‚úì Injected' if has_tools else '‚úó Missing'}")


def test_custom_prompts():
    """Test custom prompt loading."""
    print("\n" + "=" * 80)
    print("CUSTOM PROMPT TEST")
    print("=" * 80)

    mgr = PromptManager(prompt_style="custom")

    # Set a custom agent prompt
    custom_agent = """You are a specialized research agent.
Focus on academic sources and peer-reviewed papers.
Always include DOI links when available."""

    mgr.set_custom_prompt("agent", custom_agent)

    retrieved = mgr.get_agent_prompt()

    print(f"\n‚úÖ Custom Prompt Test:")
    print(f"  Set Length:      {len(custom_agent)} chars")
    print(f"  Retrieved Length: {len(retrieved)} chars")
    print(f"  Match:           {'‚úì Exact match' if custom_agent == retrieved else '‚úó Mismatch'}")


def run_all_tests():
    """Run all tests."""
    print("\n" + "=" * 80)
    print("üß™ PROMPT COMPARISON TEST SUITE")
    print("=" * 80)

    try:
        test_prompt_lengths()
        test_prompt_content()
        test_context_injection()
        test_custom_prompts()

        print("\n" + "=" * 80)
        print("‚úÖ ALL TESTS COMPLETED")
        print("=" * 80)

        print("\nüìù RECOMMENDATIONS:")
        print("  1. Enhanced prompts add ~600 tokens per call")
        print("  2. Cost increase is minimal (~$0.00003 per call)")
        print("  3. Quality improvement is significant (better citations, structure)")
        print("  4. Use 'enhanced' for production, 'simple' for testing")
        print("  5. Custom prompts allow for domain-specific optimization")

    except Exception as e:
        print(f"\n‚ùå TEST FAILED: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_all_tests()
